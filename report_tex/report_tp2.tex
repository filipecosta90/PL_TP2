%
% Layout retirado de http://www.di.uminho.pt/~prh/curplc09.html#notas
%

\documentclass{report}
\usepackage[portuges]{babel}
\usepackage[latin1]{inputenc}

\usepackage{url}
\usepackage{listings}
\lstset{
  basicstyle=\small,
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    breaklines=true,
    frame=tB,
    mathescape=true,
    escapeinside={(*@}{@*)}
}

    \usepackage{xspace}
    \usepackage{graphicx}
    \usepackage{float}

    \parindent=0pt
    \parskip=2pt

    \setlength{\oddsidemargin}{-1cm}
    \setlength{\textwidth}{18cm}
    \setlength{\headsep}{-1cm}
    \setlength{\textheight}{23cm}

    \def\darius{\textsf{Darius}\xspace}
    \def\java{\texttt{Java}\xspace}
    \def\pe{\emph{Publicação Eletrónica}\xspace}


    \title{Processamento de Linguagens (3º ano de Curso)\\ \textbf{Trabalho Prático N 2}\\ Relatório de Desenvolvimento}
    \author{Filipe Costa Oliveira\\ a57816  }
    \date{\today}

    \begin{document}

    \maketitle

    \newpage

    \tableofcontents

    \chapter{Introdução} \label{intro}

    O presente trabalho prático foca-se no desenvolvimento de  um compilador, que tem como fonte uma linguagem de alto nível (também esta desenvolvida especificamente para este trabalho prático) , gerando código para uma máquina de stack virtual. \par 
    Um compilador comum divide o processo de tradução em várias fases. Para o propósito específico desta unidade curricular iremos focar-nos nas seguintes:
    \begin{itemize}
    \item 1ª Fase de tradução -- Análise Léxica, que agrupa sequências de caracteres em tokens. Recorreremos nesta fase à definição das expressões regulares que permitem definir os tokens.
    \item 2ª Fase de tradução --  Reconhecimento(Parsing) da estrutura gramatical do programa, através do agrupamento dos tokens em produções. Recorreremos à definição de uma gramática independente de contexto por forma a definir as estruturas de programa válidas a reconhecer pelo parser. Denote que juntamente com o parsing é realizada a análise semântica, assim como a geração de código associando regras às produções anteriormente descritas.
    \end{itemize} 
    Começaremos portanto por definir uma linguagem de programação imperativa simples, que chamaremos Algebra. A Algebra permitirá:
    \begin{itemize}
    \item declarar e manusear variáveis atómicas do tipo inteiro, com os quais se podem realizar as habituais operações
aritméticas, relacionais e lógicas.
    \item declarar e manusear variáveis estruturadas do tipo array (a 1 ou 2 dimensões) de inteiros, em relação aos quais  é apenas permitida a operação de indexação. Aos arrays de duas dimensões, por se tratar de uma linguagem algébrica, chamaremos matrizes, dada a fácil associação a este tipo de variável à sua definição análoga da álgebra linear.
    \item efetuar instruções algorítmicas básicas como a atribuição de expressões a variáveis.
\item ler do standard input e escrever no standard output.
\item  efetuar instruções para controlo do fluxo de execução -- condicional e cíclica -- que possam ser aninhadas.
\item definir e invocar subprogramas sem parâmetros mas que possam retornar um resultado atómico.
    \end{itemize} 
  
Na nossa linguagem de programação por questões de estruturação e percepção, teremos como premissa que as varíaveis deverão ser declaradas no início do programa, não podendo haver re-declarações, nem utilizações sem declaração prévia. Não será permitida a declaração e associação de um valor inteiro na mesma instrução. Achamos essa solução pouco elegante. Assim, todas as variáveis terão o valor zero após a declaração.\par 

Será desenvolvido portanto o compilador para a Algebra, com base na GIC criada acima e recurso ao Gerador Yacc/ Flex.O compilador de Algebra irá gerar pseudo-código, Assembly da Máquina Virtual VM cuja documentação completaestá disponibilizada em anexo.\par
Por forma a facilitar e validar o trabalho, à medida que as funcionalidades forem descritas serão apensados  exemplos ilustrativos. \par 
Por fim, serão apresentados um conjunto de testes mais complexos(programas-fonte diversos e respectivo código produzido), que tentam testar de uma forma mais alargadas as funcionalidades da Algebra, sendo estes:
\begin{itemize}
\item lidos 3 números, escrever o maior deles. \item ler N (valor dado) números e calcular e imprimir o seu somatório. \item contar e imprimir os números pares de uma sequência de N números dados. \item ler e armazenar os elementos de um vetor de comprimento N, imprimido os valores por ordem crescente após fazera ordenação do array por trocas diretas. \item ler e armazenar os elementos de uma matriz NxM, calculando e imprimindo de seguida a média e máximo dessa matriz.\item  invocar e usar num programa  uma função.

    \end{itemize} 



    \chapter{Filtro de Texto com o Flex para ler uma ontologia descrita em OWL}
    \label{filtro}
    \section{Concepção/desenho da Resolução}
    Tal como descrito anteriormente o problema será resolvido com recurso à ferramenta Flex. Pretendemos então analisar uma ontologia descrita em OWL e  desenhar um grafo que ligue os conceitos entre si. Denote que a ontologia descrita em OWL não passa de um dialecto XML, sendo portanto standardizada a forma como extraímos os dados. \par 
    Apesar da linguagem OWL ser extremamente extensa, apenas nos interessam a identificação das classes propriamente ditas e as relações entre estas, por forma a podermos desenhar o grafo que descreve a ontologia.\par 

    \section{Padrões de frases a encontrar, através de ER}
    Podemos considerar que no contexto do problema apresentado temos especial interesse nos axiomas de propriedades de dados, objectos, e classes.
    Assim, os axiomas passíveis de serem incluídos no grafo serão:
    \begin{itemize}
    \item \textbf{Axiomas de Objetos}
    \begin{verbatim}
ObjectPropertyAxiom :=
SubObjectPropertyOf | EquivalentObjectProperties |
DisjointObjectProperties | InverseObjectProperties |
ObjectPropertyDomain | ObjectPropertyRange |
FunctionalObjectProperty | InverseFunctionalObjectProperty |
ReflexiveObjectProperty | IrreflexiveObjectProperty |
SymmetricObjectProperty | AsymmetricObjectProperty |
TransitiveObjectProperty
\end{verbatim}

\item \textbf{Axiomas de Dados}
\begin{verbatim}
DataPropertyAxiom :=
SubDataPropertyOf | EquivalentDataProperties | DisjointDataProperties |
DataPropertyDomain | DataPropertyRange | FunctionalDataProperty
\end{verbatim}
\item \textbf{Axiomas de Classe}
\begin{verbatim}
ClassAxiom := 
SubClassOf | EquivalentClasses | 
DisjointClasses | DisjointUnion
\end{verbatim}

\end{itemize}

que serão convertidos nas seguintes definições de expressões regulares a serem utilizadas no Flex:
\begin{lstlisting}
OBJ_PROP_AXIOM SubObjectPropertyOf|EquivalentObjectProperties|DisjointObjectProperties|InverseObjectProperties|ObjectPropertyDomain|ObjectPropertyRange|FunctionalObjectProper

DAT_PROP_AXIOM SubDataPropertyOf|EquivalentDataProperties|DisjointDataProperties|DataPropertyDomain|DataPropertyRange|FunctionalDataProperty

CLA_PROP_AXIOM SubClassOf|EquivalentClasses|DisjointClasses|DisjointUnion
\end{lstlisting}


\subsection{Comutação de contextos em Flex através de start conditions}
Por forma a realizar a correta análise dos padrões de texto foi necessário adicionar start conditions às regras das expressões regulares. Deste modo, apresenta-se a lista de todas as start conditions utilizadas e sua breve descrição:

\begin{lstlisting}

%x IN_PROP IN_DATA RELATION RELATION_BEG_END DATA DATA_BEG_END VALUE IN_CLASS CLASS_BEG_END 
\end{lstlisting}

\begin{itemize}
\item  IN\_PROP  -- define o contexto de leitura de Axiomas de Objetos 
\item RELATION -- define o contexto de inicio da leitura de Relação de Objetos 
\item RELATION\_BEG\_END -- define o contexto de inicio  da leitura do primeiro e segundo objectos na Relação de Objetos 



\vspace{1cm}
\item IN\_DATA -- define o contexto de leitura de Axiomas de Dados
\item DATA -- define o contexto do início da leitura dos  Dados
\item DATA\_BEG\_END -- define o contexto de inicio  da leitura da classe envolvida no Axioma de Dados 
\item VALUE -- define o contexto de inicio  da leitura do datatype envolvido no Axioma de Dados 

\vspace{1cm}

\item IN\_CLASS -- define o contexto de leitura de Axiomas de Classes
\item CLASS\_BEG\_END -- define o contexto de inicio  da leitura da primeira e segunda classes na Relação de Classes 
\end{itemize}

\subsection{Expressões Regulares e acções resultantes}
\label{1er}
Definidas as start conditions, resta-nos explicitar todas as expressões regulares, incluindo aquelas que dão início à comutação entre contextos do flex.
\begin{lstlisting}
[^<> ]*<{DAT_PROP_AXIOM}> { BEGIN IN_DATA; }
[^<> ]*<{OBJ_PROP_AXIOM}> { BEGIN IN_PROP; }
[^<> ]*<{CLA_PROP_AXIOM}> { BEGIN IN_CLASS; }

<IN_CLASS>[^<>]*<Class[ \t\n]*IRI=\" {BEGIN CLASS_BEG_END;}
<IN_CLASS><\/{CLA_PROP_AXIOM} {BEGIN INITIAL;}
<IN_CLASS>.|\n {;}

<CLASS_BEG_END>[^">]+/\" {
if ( class_subclass == NULL ){
  class_subclass = strdup(yytext);
}
else{
  class_class = strdup(yytext);
  print_class();
} 
}

<CLASS_BEG_END>\/> { BEGIN IN_CLASS;  }
<CLASS_BEG_END>.|\n {;}

<DATA>[^">]+/\" {data=strdup(yytext);} 
<DATA>\/> {BEGIN IN_DATA;}
<DATA>.|\n {;}

<IN_DATA>[^<>]*<DataProperty[ \t\n]*IRI=\" { BEGIN DATA;}
<IN_DATA>[^<>]*<Class[ \t\n]*IRI=\" { BEGIN DATA_BEG_END;}
<IN_DATA>[^<>]*<Datatype[ \t\n]*abbreviatedIRI=\" {  BEGIN VALUE;}
<IN_DATA><\/{DAT_PROP_AXIOM} {BEGIN INITIAL;}
<IN_DATA>.|\n {;}

<VALUE>[^"<>]+/\" { value = strdup(yytext); print_data(); }
<VALUE>\/> {BEGIN IN_DATA;}
<VALUE>.|\n {;}

<DATA_BEG_END>[^">]+/\" { class = strdup(yytext); }
<DATA_BEG_END>\/> {BEGIN IN_DATA;}
<DATA_BEG_END>.|\n {;}

<IN_PROP>[^<>]*<ObjectProperty[ \t\n]*IRI=\" { BEGIN RELATION;  }
<IN_PROP>[^<>]*<Class[ \t\n]*IRI=\" {  BEGIN RELATION_BEG_END;}
<IN_PROP><\/{OBJ_PROP_AXIOM} { BEGIN INITIAL;}
<IN_PROP>.|\n {;}

<RELATION>[^"<>]+/\" { relation=strdup(yytext);} 
<RELATION>\/> { BEGIN IN_PROP;}
<RELATION>.|\n {;}

<RELATION_BEG_END>[^"<>]+/\" {
if ( begin == NULL ){
  begin = strdup(yytext);
}
else{
  end = strdup(yytext);
  print_prop();
} 
}

<RELATION_BEG_END>\/> { BEGIN IN_PROP;}
<RELATION_BEG_END>.|\n { ;}

<INITIAL>.|\n {;}
\end{lstlisting}


\section{Codificação e Testes}
\subsection{Estruturas de Dados e bibliotecas utilizadas}
Como pode verificar, não existem estruturas de dados complexas para a resolução deste problema, sendo que são apenas utilizadas strings para guardar temporariamente os valores dos dados em relação. De seguida explicitam-se todas as variáveis e bilbliotecas utilizadas:
\begin{lstlisting}
%{
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

  char* relation;
  char* begin;
  char* end;
  char* data;
  char* class;
  char* value;
  char* class_class;
  char* class_subclass;

  void print_prop();
  void print_data();
  void print_class();
  %}

  \end{lstlisting}

  \subsection{Métodos Adicionais}
  Como poderá constatar na seção \ref{1er} existem 3 métodos adicionais invocados no final da leitura completa dos axiomas de objectos, classes e dados, sendo eles de seguida explicitados:

  \begin{lstlisting}
  void print_class(){
    printf("\"%s\" [shape = box, style=rounded, fontsize=12 fontname=helvetica];\n", class_subclass);
    printf("\"%s\" [shape = box, style=rounded, fontsize=12 fontname=helvetica];\n", class_class);
    printf("\"%s\" -> \"%s\" [ label = \"SubClassOf\" , fontsize=8 , fontcolor=\"blue\", color=\"blue\" ]\n", class_subclass, class_class );
    class_subclass=NULL;
    class_class=NULL;
  }

void print_data(){
  printf("\"%s\" [shape = box, style=rounded, fontsize=12 fontname=helvetica];\n", class);
  printf("\"%s\" [shape = box, style=filled,color=\"red\", fontsize=12 fontname=helvetica];\n", value);
  printf("\"%s\" -> \"%s\" [ label = \"%s\" ]\n", class, value, data );
  class=NULL;
  value=NULL;
  data=NULL;
}

void print_prop(){
  printf("\"%s\" [shape = box, style=rounded, fontsize=12 fontname=helvetica];\n", begin);
  printf("\"%s\" -> \"%s\" [ label = \"%s\" ]\n", begin, end, relation );
  begin=NULL;
  relation=NULL;
  end=NULL;
}
\end{lstlisting}
Os métodos por si só são elucidativos, sendo que a impressão é realizada conforme a linguagem Dotty.

\subsection{Main}
Dada a simplicidade das estruturas de dados, o método main é também bastante simples, de seguida explicitado:
\begin{lstlisting}
int main(int argc, char** argv){
  graph_print();
  yylex();
  printf("}\n");
  return (0);
}
\end{lstlisting}
O código completo da ferramenta é passível de consulta na seção \ref{completo1a} na página \pageref{completo1a}.

\section{Testes realizados e Resultados}
Foi realizado um script da shell com vista a facilmente ilustrar as funcionalidades da ferramenta, sendo que essas mesma script lê o ficheiro exemplo test1.xml , criando o ficheiro ex1.gv e, a partir deste o ficheiro ex1.png, demonstrado na figura \ref{fig:ex1}.
\subsection{Shell Script}
\begin{lstlisting}
#!bin/sh

echo "/*
********************************************************************************
*Copyright(C) 2016 Filipe Oliveira, Universidade do Minho
*   All Rights Reserved.
*
********************************************************************************
*   Content : simple tool 1a) functionality script 
*
*
********************************************************************************/"

make clean
flex owl_graph.l
make 
./owl_graph < test1.xml > ex1.gv
dot ex1.gv -Tpng > ex1.png
echo "##########################"
echo ">>>>>>>> ex1 in ex1.png"
echo "         opening file"
echo "##########################"
open ex1.png
echo "done"
\end{lstlisting}

\subsection{Ficheiro Exemplo de input no formato OWL}
\begin{lstlisting}
<ObjectPropertyDomain>
<ObjectProperty IRI="#receives"/>
<Class IRI="#Laundry"/>
</ObjectPropertyDomain>
<ObjectPropertyRange>
<Annotation>
<AnnotationProperty abbreviatedIRI="owl:backwardCompatibleWith"/>
<IRI>#Laundry</IRI>
</Annotation>
<ObjectProperty IRI="#receives"/>
<Class IRI="#Order"/>
</ObjectPropertyRange>

<ObjectPropertyDomain>
<ObjectProperty IRI="#works"/>
<Class IRI="#Worker"/>
</ObjectPropertyDomain>
<ObjectPropertyRange>
<Annotation>
<AnnotationProperty abbreviatedIRI="owl:backwardCompatibleWith"/>
<IRI>#Worker</IRI>
</Annotation>
<ObjectProperty IRI="#works"/>
<Class IRI="#Laundry"/>
</ObjectPropertyRange>


<ObjectPropertyDomain>
<ObjectProperty IRI="#owns"/>
<Class IRI="#Client"/>
</ObjectPropertyDomain>
<ObjectPropertyRange>
<Annotation>
<AnnotationProperty abbreviatedIRI="owl:backwardCompatibleWith"/>
<IRI>#Client</IRI>
</Annotation>
<ObjectProperty IRI="#owns"/>
<Class IRI="#Order"/>
</ObjectPropertyRange>

<SubClassOf>
<Class IRI="#Laundry"/>
<Class IRI="#Stores"/>
</SubClassOf>
<SubClassOf>
<Class IRI="#Owner"/>
<Class IRI="#Person"/>
</SubClassOf>

<DataPropertyDomain>
<DataProperty IRI="#material"/>
<Class IRI="#Type"/>
</DataPropertyDomain>
<DataPropertyRange>
<DataProperty IRI="#material"/>
<Datatype abbreviatedIRI="xsd:string"/>
</DataPropertyRange>

<DataPropertyDomain>
<DataProperty IRI="#orderid"/>
<Class IRI="#Order"/>
</DataPropertyDomain>
<DataPropertyRange>
<DataProperty IRI="#orderid"/>
<Datatype abbreviatedIRI="xsd:string"/>
</DataPropertyRange>
<SubClassOf>
<Class IRI="#Client"/>
<Class IRI="#Person"/>
</SubClassOf>
<SubClassOf>
<Class IRI="#Worker"/>
<Class IRI="#Person"/>
</SubClassOf>

\end{lstlisting}


\subsection{Grafo exemplo resultante}
\begin{figure}[H]
\centering
\includegraphics[width=0.5\columnwidth]{PNG/ex1}
\caption{Grafo exemplo criado com as relações entre classes a partir da análise do ficheiro test1.xml }
\label{fig:ex1}
\end{figure}




\chapter{Normalizador de ficheiros BibTeX}
\label{normalizador}


\section{Concepção/desenho da Resolução}
Tal como descrito anteriormente o problema será resolvido com recurso à ferramenta Flex. 
Pretendemos então analisar documentos BibTeX e:

\begin {itemize}
\item fazer a contagem das categorias(phDThesis, Misc, InProceeding, etc.) que ocorrem no documento, produzindo um documento em formato HTML com o nome das categorias encontradas e respectivas contagens;
\item Desenvolva uma ferramenta de normalização (sempre que um campo está entre aspas, trocar para chavetas e escrever o nome dos autores no formato "N. Apelido"), fazendo ainda uma ferramenta de pretty-printing que indente corretamente cada campo, escreva um autor por linha e colocando sempre no início os campos autor e título.
\item Construir um Grafo que mostre, para um dado autor (escolhido pelo utilizador) todos os autores que publicam
normalmente com o autor em causa, recorrendo uma vez mais à linguagem Dot do GraphViz2.
\end{itemize}
Para foram produzidos 3 ficheiros (bib\_norm\_1.l, bib\_norm\_2.l, bib\_norm\_3.l), um para cada alínea por forma a tornar de mais fácil compreensão o papel de cada expressão regular, start condition, ou estrutura de dados na solução geral. Facilmente se combinam os 3 ficheiros em 1, mas dado o propósito académico da ferramenta julgo ser fulcral a compreensão do anteriormente descrito em cada ficheiro e alínea do problema.

\section{alínea a) ficheiro bib\_norm\_1.l }
\subsection{Padrões de frases a encontrar, através de ER}
Podemos considerar que no contexto do problema apresentado temos interesse apenas na contagem das categorias, que serão facilmente encontradas com base nas seguintes definições de expressões regulares a serem utilizadas no Flex:

\begin{lstlisting}
LETRA [A-Za-z]
CATEG \@{LETRA}+\{
LETRA_NUM [0-9A-Za-z]
ID ({LETRA_NUM}|:)+
\end{lstlisting}


\subsubsection{Expressões Regulares e acções resultantes}

Resta-nos explicitar todas as expressões regulares e respectivas acções resultantes:

\begin{lstlisting}
%%
{CATEG}/[^=]*,      {
  yytext++; yytext[yyleng-2]='\0';
  char* key = g_ascii_strdown (yytext, yyleng-2);
  if ( g_hash_table_contains ( table ,(void*) key ) ){
    int value;
    value = GPOINTER_TO_INT( g_hash_table_lookup ( table,(void*) key));
    value++;
    g_hash_table_replace (  table, (void*) key,GINT_TO_POINTER(value) );
  }
  else {
    int value = 1;
    gboolean add_result = g_hash_table_insert (  table, (void*) key,  GINT_TO_POINTER(value) );
  }
                    }
.|\n|\t { ; }
%%
\end{lstlisting}


\subsection{Codificação }
\subsubsection{Estruturas de Dados e bibliotecas utilizadas}
Como pode verificar foi necessário recorrer a  estruturas de dados complexas para a resolução deste problema, nomeadamente hash tables. Ora, segundo o conselho do professor José João, foi reutilizado código da biblioteca da GLib, biblioteca essa extremamente otimizada.
De seguida explicitam-se todas as variáveis e bibliotecas utilizadas:
\begin{lstlisting}
%{
  /*
   ********************************************************************************
   *   Copyright(C) 2016 Filipe Oliveira, Universidade do Minho
   *   All Rights Reserved.
   *
   ********************************************************************************
   *   Content : Simple bibtex category counter (phDThesis, Misc, InProceeding,
   *             etc.), that occur in a document
   ********************************************************************************/

#include <stdio.h>
#include <glib.h>
#include <stdlib.h>
#include <string.h>

  //HashTable
  GHashTable *table; 

  %}
  \end{lstlisting}

  \subsubsection{Métodos Adicionais}
  Como poderá constatar na seção \ref{1er} existe 1 método adicional invocado no final da leitura ficheiro, tendo por função imprimir o par ( chave -- valor ) num formato de lista HTML, sendo a chave a categoria BibTeX e o valor o número de ocorrências da mesma no ficheiro:

  \begin{lstlisting}
  static void print_key_value(gpointer key, gpointer value, gpointer userdata){
    int val = (int) value;
    char* ke = (char*) key;
    printf("<li>%s : %d</li>\n", ke, val);
  }
\end{lstlisting}

\subsubsection{Main}
Dada a simplicidade do analisador, o método main é também bastante simples, apenas imprimindo as tags HTML e inicializando a hashtable. Passaremos de seguida a explicitá-lo:
\begin{lstlisting}

int main(){
  table = g_hash_table_new(g_str_hash, g_str_equal);
  yylex();
  printf("<!DOCTYPE html>\n<html>\n<body>\n<ul>\n");
  g_hash_table_foreach(table,print_key_value, NULL );
  printf("</ul>\n</body>\n</html>\n");
  return (0);
}
\end{lstlisting}
O código completo da ferramenta é passível de consulta na seção \ref{completo2a} na página \pageref{completo2a}.



%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%


\section{alínea b) ficheiro bib\_norm\_2.l }
\subsection{Padrões de frases a encontrar, através de ER}
Podemos considerar que no contexto do problema apresentado temos interesse em todos os campos de cada entrada, sendo que teremos de tratar especialmente os campos author e title. Tal tarefa é facilitada com base nas seguintes definições de expressões regulares a serem utilizadas no Flex:

\begin{lstlisting}
LETRA [A-Za-z]
LETRA_NUM [0-9A-Za-z]
NUM [0-9]
CATEG \@{LETRA}+\{
FIELD_ID ^[^,}"][^=]*=[ \t]*
FIELD_BREAK [^=]*[ \t\n]*(\"|\})
FIELD_BREAK_NUM [^=\}]*\}?
FIELD_START [\{\"]
AUTHOR_ID ^[ \t]*[Aa][Uu][Tt][Hh][Oo][Rr][ \t]*=[ \t]*
TITLE_ID ^[ \t]*[Tt][Ii][Tt][Ll][Ee][ \t]*=[ \t]*
AUTHOR_SEP [ \t]and[ \t]
AUTHOR_BREAK [^=]+(\"|\})
\end{lstlisting}


\subsubsection{Comutação de contextos em Flex através de start conditions}
Por forma a realizar a correta análise dos padrões de texto foi necessário adicionar start conditions às regras das expressões regulares. Deste modo, apresenta-se a lista de todas as start conditions utilizadas:

\begin{lstlisting}
%x INSIDE IN_AUTHOR IN_FIELD_TXT IN_FIELD_NUM AUTHOR_DIV START_AUTHOR
\end{itemize}

\subsubsection{Expressões Regulares e acções resultantes}
\label{2ber}
Definidas as start conditions, resta-nos explicitar todas as expressões regulares, incluindo aquelas que dão início à comutação entre contextos do flex.
\begin{lstlisting}
%%

{CATEG}[^=]*,            {
  printf("%s\n",yytext);
  BEGIN INSIDE;
                         }

<INSIDE>{TITLE_ID}{FIELD_START}  {   
  yytext[yyleng-2]='\0';
  title_key = strdup ( yytext );
  title_key = g_strchomp ( title_key );
  title_key = g_strchug ( title_key );
  field_id = strdup(title_key);
  BEGIN IN_FIELD_TXT;}

  <INSIDE>{AUTHOR_ID}{FIELD_START}  {   
    yytext[yyleng-2]='\0';
    author_key = strdup ( yytext );
    author_key = g_strchomp ( author_key );
    author_key = g_strchug ( author_key );
    BEGIN START_AUTHOR;
  }

<INSIDE>{FIELD_ID}/{LETRA_NUM}  {   
  yytext[yyleng-1]='\0';
  field_id = strdup ( yytext );
  field_id = g_strchomp ( field_id );
  field_id = g_strchug ( field_id );
  BEGIN IN_FIELD_NUM; }

  <INSIDE>{FIELD_ID}{FIELD_START}  {   
    yytext[yyleng-2]='\0';
    field_id = strdup ( yytext );
    field_id = g_strchomp ( field_id );
    field_id = g_strchug ( field_id );
    BEGIN IN_FIELD_TXT;
  }

<INSIDE>[ \n\t]*, { BEGIN INSIDE; }
<INSIDE>[ \n\t]*\} { BEGIN INITIAL; }
<INSIDE>.|\n { BEGIN INSIDE;}

<START_AUTHOR>.          {
  author_initial = (char*) malloc ( 4* sizeof(char));
  author_initial[0] = yytext[0];
  author_initial[1] = '.';
  author_initial[2]=' ';
  author_initial[3]='\0';
  BEGIN IN_AUTHOR;
}

<IN_AUTHOR>[^= \n\t]*/[ ]and[ ]     {   
  author_lastname = strdup ( yytext );
  author_lastname = g_strchomp ( author_lastname );
  author_lastname = g_strchug ( author_lastname );
  char *initial_plus_lastname;
  int size = strlen(author_lastname);
  size += strlen( author_initial) + 1;
  initial_plus_lastname = (char*) malloc ( size * sizeof(char));
  strcpy(initial_plus_lastname, author_initial);
  strcat(initial_plus_lastname, author_lastname);
  g_hash_table_insert (  authors_table, (void*) initial_plus_lastname,   GINT_TO_POINTER (0) );
  BEGIN AUTHOR_DIV;
}

<IN_AUTHOR>[^= \n\t]*[ \t]?(\"|\})/,    { 
yytext[yyleng-1]='\0';
author_lastname = strdup ( yytext );
author_lastname = g_strchomp ( author_lastname );
author_lastname = g_strchug ( author_lastname );
char *initial_plus_lastname;
int size = strlen(author_lastname);
size += strlen( author_initial) + 1;
initial_plus_lastname = (char*) malloc ( size * sizeof(char));
strcpy(initial_plus_lastname, author_initial);
strcat(initial_plus_lastname, author_lastname);
g_hash_table_insert (  authors_table, (void*) initial_plus_lastname,   GINT_TO_POINTER (0) );
BEGIN AUTHOR_DIV;
}

<IN_AUTHOR>.              { ; }

<AUTHOR_DIV>,             { BEGIN INSIDE; }

<AUTHOR_DIV>[ ]and[ ]     { BEGIN START_AUTHOR; }


<IN_FIELD_NUM>{FIELD_BREAK_NUM}[ \n\t\r]*\} {
  yytext[yyleng-1]='\0';
  field = strdup(yytext);
  field = g_strchomp ( field );
  field = g_strchug ( field );
  g_hash_table_insert (  num_fields_table, (void*) field_id,  (void*) field );
  pretty_print();
  BEGIN INITIAL;
}

<IN_FIELD_NUM>{FIELD_BREAK_NUM}[ \n\t\r]*(#[^,=]*)?, {
  yytext[yyleng-1]='\0';
  field = strdup(yytext);
  field = g_strchomp ( field );
  field = g_strchug ( field );
  g_hash_table_insert (  num_fields_table, (void*) field_id,  (void*) field );
  BEGIN INSIDE;
}

<IN_FIELD_TXT>{FIELD_BREAK}[ \n\t\r]*\} {
  yytext[yyleng-2]='\0';
  field = strdup(yytext);
  field = g_strchomp ( field );
  field = g_strchug ( field );
  g_hash_table_insert (  txt_fields_table, (void*) field_id,  (void*) field );
  BEGIN INITIAL;
  pretty_print();
}

<IN_FIELD_TXT>{FIELD_BREAK}[ \n\t\r]*(#[^,=]*)?, {
  yytext[yyleng-2]='\0';
  field = strdup(yytext);
  field = g_strchomp ( field );
  field = g_strchug ( field );
  g_hash_table_insert (  txt_fields_table, (void*) field_id,  (void*) field );
  BEGIN INSIDE;
}

<IN_FIELD_TXT>.|\n {;}
<IN_FIELD_NUM>.|\n {;}

{CATEG}[^\n]*\}             { printf("%s\n",yytext);}

<INITIAL>.|\n {;}

%%
\end{lstlisting}



\subsection{Codificação }
\subsubsection{Estruturas de Dados e bibliotecas utilizadas}
Como pode verificar foi necessário recorrer a  estruturas de dados complexas para a resolução deste problema, nomeadamente hash tables. Ora, segundo o conselho do professor José João, foi reutilizado código da biblioteca da GLib, biblioteca essa extremamente otimizada.
De seguida explicitam-se todas as variáveis e bibliotecas utilizadas:
\begin{lstlisting}
%{
  /*
   ********************************************************************************
   *   Copyright(C) 2016 Filipe Oliveira, Universidade do Minho
   *   All Rights Reserved.
   *
   ********************************************************************************
   *   Content : 2b) bibtex file normalizer and pretty-printer
   ********************************************************************************/

#include <stdio.h>
#include <glib.h>
#include <stdlib.h>
#include <string.h>

  //HashTable
  GHashTable *txt_fields_table; 
  GHashTable *num_fields_table; 
  GHashTable *authors_table; 
  char* field_id;
  char* field;
  char* author_id = "author";
  char* title_id = "title";
  char* author_key;
  char* title_key;
  char* author_initial;
  char* author_lastname;

  //function sig
  void pretty_print();

  %}
  \end{lstlisting}

  \subsubsection{Métodos Adicionais}
  Como poderá constatar na seção \ref{1er} existe 1 métodos adicional invocado no final da leitura de cada entrada do ficheiro, tendo por função imprimir o registo num formato normalizado:

  \begin{lstlisting}
  %{
    void pretty_print(){
      int field_num = 0;
      char* current_value;

      GHashTableIter iter;
      gpointer key, value;

      if( title_key != NULL ){
        current_value =  g_hash_table_lookup ( txt_fields_table,(void*) title_key);
        g_hash_table_remove ( txt_fields_table, (void*) title_key);
        printf("\t%s {%s}", title_key, current_value);
        field_num++;
      }

      if ( author_key != NULL ){
        if(field_num > 0){ printf(",\n"); }
        printf("\t%s {", author_key);
        int number_authors = g_hash_table_size ( authors_table );
        int author_num = 1;
        g_hash_table_iter_init (&iter, authors_table );
        while (g_hash_table_iter_next (&iter, &key, &value)){
          if(author_num > 1 ){ printf("\n\t\tand "); }
          char* name = (char*) key;
          printf("%s", name);
          g_hash_table_iter_remove (&iter);
          author_num++;
        } 
        printf("}");
        field_num++;
      }

      int size = g_hash_table_size ( txt_fields_table );
      size += g_hash_table_size ( num_fields_table );
      g_hash_table_iter_init (&iter, txt_fields_table );
      while (g_hash_table_iter_next (&iter, &key, &value)){
        if(field_num > 0 ){ printf(",\n"); }
        char* val = (char*) value;
        char* ke = (char*) key;
        printf("\t%s {%s}", ke, val);
        g_hash_table_iter_remove (&iter);
      } 

      g_hash_table_iter_init (&iter, num_fields_table );
      while (g_hash_table_iter_next (&iter, &key, &value)){
        if(field_num > 0 ){ printf(",\n"); }
        char* val = (char*) value;
        char* ke = (char*) key;
        printf("\t%s %s", ke, val);
        g_hash_table_iter_remove (&iter);
      }
      printf("\n}\n\n");
    }
    \end{lstlisting}

    \subsubsection{Main}
    O método main é também bastante simples, apenas inicializando as hashtables. Passaremos de seguida a explicitá-lo:
      \begin{lstlisting}
    int main(){
      txt_fields_table = g_hash_table_new(g_str_hash, g_str_equal);
      num_fields_table = g_hash_table_new(g_str_hash, g_str_equal);
      authors_table = g_hash_table_new(g_str_hash, g_str_equal);
      yylex();
      return (0);
    }
    \end{lstlisting}
    O código completo da ferramenta é passível de consulta na seção \ref{completo2b} na página \pageref{completo2a}.


      %%%%%%%%%%%%%%%%%
      %%%%%%%%%%%%%%%%%
      %%%%%%%%%%%%%%%%%


      \section{alínea c) ficheiro bib\_norm\_3.l }
    \subsection{Padrões de frases a encontrar, através de ER}
    Podemos considerar que no contexto do problema apresentado temos interesse no campo author de cada  entrada, ou seja, podemos reaproveitar grande parte do trabalho desenvolvido na alínea anterior. Tal tarefa é facilitada com base nas seguintes definições de expressões regulares a serem utilizadas no Flex:

      \begin{lstlisting}
    LETRA [A-Za-z]
      LETRA_NUM [0-9A-Za-z]
      NUM [0-9]
      CATEG \@{LETRA}+\{
      FIELD_START [\{\"]
      AUTHOR_ID [ \t]*[Aa][Uu][Tt][Hh][Oo][Rr][ \t]*=[ \t]*
      AUTHOR_SEP [ \t]and[ \t]
      AUTHOR_BREAK [^=]+(\"|\})
      \end{lstlisting}


    \subsubsection{Comutação de contextos em Flex através de start conditions}
    Por forma a realizar a correta análise dos padrões de texto foi necessário adicionar start conditions às regras das expressões regulares. Deste modo, apresenta-se a lista de todas as start conditions utilizadas:

      \begin{lstlisting}
    %x INSIDE IN_AUTHOR IN_FIELD_TXT IN_FIELD_NUM AUTHOR_DIV START_AUTHOR
      \end{itemize}

    \subsubsection{Expressões Regulares e acções resultantes}
    \label{2cer}
    Definidas as start conditions, resta-nos explicitar todas as expressões regulares, incluindo aquelas que dão início à comutação entre contextos do flex.
      \begin{lstlisting}
    %%

    {CATEG}[^=]*,           { BEGIN INSIDE; }

    <INSIDE>{AUTHOR_ID}{FIELD_START}  {   
      yytext[yyleng-2]='\0';
      author_key = strdup ( yytext );
      author_key = g_strchomp ( author_key );
      author_key = g_strchug ( author_key );
      BEGIN START_AUTHOR;
    }

    <INSIDE>[ \n\t]*,       { BEGIN INSIDE; }
    <INSIDE>[ \n\t]*\}      { BEGIN INITIAL; }

    <INSIDE>.|\n              { BEGIN INSIDE;}

    <START_AUTHOR>.           {
      author_initial = (char*) malloc ( 4* sizeof(char));
      author_initial[0] = yytext[0];
      author_initial[1] = '.';
      author_initial[2]=' ';
      author_initial[3]='\0';
      BEGIN IN_AUTHOR;
    }

    <IN_AUTHOR>[^= \n\t]*/[ ]and[ ]     {   
      author_lastname = strdup ( yytext );
      author_lastname = g_strchomp ( author_lastname );
      author_lastname = g_strchug ( author_lastname );
      char *initial_plus_lastname;
      int size = strlen(author_lastname);
      size += strlen( author_initial) + 1;
      initial_plus_lastname = (char*) malloc ( size * sizeof(char));
      strcpy(initial_plus_lastname, author_initial);
      strcat(initial_plus_lastname, author_lastname);
      g_hash_table_insert (  authors_table, (void*) initial_plus_lastname,   GINT_TO_POINTER (0) );
      BEGIN AUTHOR_DIV;
    }

    <IN_AUTHOR>[^= \n\t]*[ \t]?(\"|\})/,    { 
      yytext[yyleng-1]='\0';
    author_lastname = strdup ( yytext );
    author_lastname = g_strchomp ( author_lastname );
    author_lastname = g_strchug ( author_lastname );
    char *initial_plus_lastname;
    int size = strlen(author_lastname);
    size += strlen( author_initial) + 1;
    initial_plus_lastname = (char*) malloc ( size * sizeof(char));
    strcpy(initial_plus_lastname, author_initial);
    strcat(initial_plus_lastname, author_lastname);
    g_hash_table_insert (  authors_table, (void*) initial_plus_lastname,   GINT_TO_POINTER (1) );
    BEGIN AUTHOR_DIV;
  }

  <IN_AUTHOR>.              { ; }
  <AUTHOR_DIV>,             { check_authors(); BEGIN INSIDE; }
  <AUTHOR_DIV>[ ]and[ ]             { BEGIN START_AUTHOR; }
  <INITIAL>.|\n {;}

  %%
    \end{lstlisting}



  \subsection{Codificação }
  \subsubsection{Estruturas de Dados e bibliotecas utilizadas}
  Como pode verificar foi necessário recorrer a  estruturas de dados complexas para a resolução deste problema, nomeadamente hash tables. Ora, segundo o conselho do professor José João, foi reutilizado código da biblioteca da GLib, biblioteca essa extremamente otimizada.
    De seguida explicitam-se todas as variáveis e bibliotecas utilizadas:
    \begin{lstlisting}
  %{

    /*
     ********************************************************************************
     *   Copyright(C) 2016 Filipe Oliveira, Universidade do Minho
     *   All Rights Reserved.
     *
     ********************************************************************************
     *   Content : 2c) bibtex co-authoring graph builder for a given normalized.
     *             author name.
     ********************************************************************************/

#include <stdio.h>
#include <glib.h>
#include <stdlib.h>
#include <string.h>

    //HashTable
    GHashTable *authors_table; 
    GHashTable *coauthors_table; 
    char* author_key;
    char* author_initial;
    char* author_lastname;
    char* author_name; 
    //function sig
    void print_graph();
    void check_authors();

    %}
    \end{lstlisting}

    \subsubsection{Métodos Adicionais}
    Como poderá constatar na seção \ref{1er} existem 2 métodos adicionais. Um (check\_authors()) invocado no final da leitura de cada entrada do ficheiro, tendo por função verificar se o autor em causa está referenciado no artigo e se sim, calcular o mapa dos seus co-autores. O outro método (graph\_print()) é invocado aquando da impressão do grafo no format Dot:

      \begin{lstlisting}

    void check_authors(){
      if ( g_hash_table_contains ( authors_table ,(void*) author_name ) ){
        g_hash_table_remove( authors_table, author_name );
        GHashTableIter iter;
        gpointer key, value;
        g_hash_table_iter_init (&iter, authors_table );
        while (g_hash_table_iter_next (&iter, &key, &value)){
          char* coauthor_name = (char*) key;
          int number_entries = 0;
          if ( g_hash_table_contains ( coauthors_table ,key ) ){
            number_entries = GPOINTER_TO_INT( g_hash_table_lookup ( coauthors_table , key));
            number_entries++;
            g_hash_table_replace (  coauthors_table, key, GINT_TO_POINTER( number_entries ) );
          }
          else{
            number_entries++;
            g_hash_table_insert (  coauthors_table, key,   GINT_TO_POINTER (number_entries) );
          }
        }
      }
      g_hash_table_remove_all( authors_table );
    }

    void graph_print(){

      GHashTableIter iter;
      gpointer key, value;
      g_hash_table_iter_init (&iter, coauthors_table );

      printf( "digraph pl_2_2_a {\n//title\nlabelloc=\"t\";\nlabel=\"%s Document collaboration and co-authoring diagram\";rankdir=TB;\nresolution=300;size=\"8,5\";", author_name);
      printf("\"%s\"[shape = box,style=filled,color=\"red\", style=rounded, fontsize=16 fontname=helvetica];\n", author_name);
      printf("node [shape = box, style=rounded, fontsize=12 fontname=helvetica]");
      while (g_hash_table_iter_next (&iter, &key, &value))
      {
        char* coauthor_name = g_str_to_ascii ((char*) key, "C");
        int number_entries = GPOINTER_TO_INT( value );
        printf("\"%s\" -> \"%s\" [ label = \"%d\" ]\n", author_name, coauthor_name, number_entries );
      }
      printf("}\n");
    } 
    \end{lstlisting}

    \subsubsection{Main}
    O método main é também bastante simples. Primeiramente  inicializa as hashtables, sendo que de seguida coloca na variável author\_name o valor do author a procurar artigos com co-autores. Após a leitura do ficheiro imprime  no formato da linguagem Dot o grafo de co-autorias. Passaremos de seguida a explicitá-lo:
      \begin{lstlisting}
    int main(int argc, char** argv){
      authors_table = g_hash_table_new(g_str_hash, g_str_equal);
      coauthors_table = g_hash_table_new(g_str_hash, g_str_equal);
      author_name = strdup(argv[1]);
      yylex();
      graph_print();
      return (0);
    }
    \end{lstlisting}
    O código completo da ferramenta é passível de consulta na seção \ref{completo2c} na página \pageref{completo2c}.



      %%%%%%%%%%%%%%%%%%%%%%%%%%%




      \section{Testes realizados e Resultados}
    Foi realizado um script da shell com vista a facilmente ilustrar as funcionalidades da ferramenta, sendo que essas mesma script lê o ficheiro exemplo lp.bib , criando os ficheiros ex2a.html, ex2b.bib e ex2c.gv. A partir do ficheiro ex2c.gv cria ainda o ficheiro ex2c.png, demonstrado na figura \ref{fig:ex2c}. 
      Na figura \ref{fig:ex2a} poderá ainda ver a página html exemplo resultante.

      \subsubsection{Shell Script}
    \begin{lstlisting}
#!bin/sh

    echo "/*
      ********************************************************************************
      *Copyright(C) 2016 Filipe Oliveira, Universidade do Minho
      *   All Rights Reserved.
      *
      ********************************************************************************
      *   Content : 2a) bibtex category counter (phDThesis, Misc, InProceeding,
        *             etc.), that occur in a document
      *           : 2b) bibtex file normalizer and pretty-printer
      *           : 2c) bibtex co-authoring graph builder for a given normalized 
      *             author name 
      ********************************************************************************/"

      make clean
      flex bib_norm_1.l
      make a1
      ./bib_norm_1 < lp.bib > ex2a.html
      echo "##########################"
      echo ">>>>>>>> ex2a in ex2a.html"
      echo "         opening file"
      echo "##########################"
      open ex2a.html

      make clean
      flex bib_norm_2.l
      make a2
      ./bib_norm_2 < lp.bib > ex2b.bib
      echo "##########################"
      echo ">>>>>>>> ex2b in ex2b.bib"
      echo "##########################"

      make clean
      flex bib_norm_3.l
      make a3
      ./bib_norm_3 "P. Henriques" < lp.bib > ex2c.gv
      dot ex2c.gv -Tpng > ex2c.png
      echo "##########################"
      echo ">>>>>>>> ex2c in ex2c.png"
      echo "         opening file"
      echo "##########################"
      open ex2c.png
      echo "done"
      \end{lstlisting}



    \subsubsection{Página HTML exemplo resultante da alínea 2a }
    \begin{figure}[H]
      \centering
      \includegraphics[width=0.5\columnwidth]{PNG/ex2a}
    \caption{Página HTML exemplo resultante da alínea 2a a partir da leitura do ficheiro lp.bib}
    \label{fig:ex2a}
    \end{figure}

    \subsubsection{Grafo exemplo resultante da alínea 2c}
    \begin{figure}[H]
      \centering
      \includegraphics[width=\columnwidth]{PNG/ex2c}
    \caption{Grafo exemplo criado com as relações de co-autoria do autor P.Henriques a partir da leitura do ficheiro lp.bib}
    \label{fig:ex2c}
    \end{figure}






    \chapter{Conclusão} \label{concl}

    Relativamente ao estado final do projecto acredito que foram cumpridos todos os requisitos, sendo que o segundo exercício foi sem dúvida o mais desafiante dada a enorme quantidade de dados e o tipo de dados em si a serem analisados. Reconhecer por si só quais as sequências de caracteres  válidas foi um desafio.\par Naturalmente que a partir da alínea 2.2.b a alínea 2.2.c foi de extrema facilidade, uma vez que todo o trabalho de análise já estava realizado. \par 
      Foi ainda tido em conta a possiblidade de recuperar de erros de leitura na alínea 2.2.b o que facilitou o input correct de dados e posterior tratamento.
      O recurso à biblioteca Glib, recomendada pelo professor José João num aula laboratorial permitiu-me ambientar ainda mais com código desenvolvido por terceiros  e sua correcta análise e integração nos meus projectos.\par 
      Faço um balanço positivo do trabalho prático, pois, apesar de ser extremamente "time consuming" retirei muito conhecimento no que da análise de dados e processamento de linguagens diz respeito.

      \appendix
      \chapter{Código do Programa da alínea 1a}
    \label{completo1a}
    \lstinputlisting{owl_graph.l} %input de um ficheiro

      \newpage
      \chapter{Código do Programa da alínea 2a}
    \label{completo2a}
    \lstinputlisting{bib_norm_1.l} %input de um ficheiro

      \newpage
      \chapter{Código do Programa da alínea 2b}
    \label{completo2b}
    \lstinputlisting{bib_norm_2.l} %input de um ficheiro


      \newpage
      \chapter{Código do Programa da alínea 3a}
    \label{completo2c}
    \lstinputlisting{bib_norm_3.l} %input de um ficheiro



      \end{document}



    \end{document} 
